{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6732d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing SimpleNN:\n",
      "Legal split points: ['net.0.bias', 'net.0.weight', 'net.2.bias', 'net.2.weight']\n",
      "Safe split points: ['net.0.bias', 'net.0.weight', 'net.2.bias', 'net.2.weight']\n",
      "  Splitting at net.0.weight ... Success.\n",
      "  Splitting at net.2.weight ... Success.\n",
      "  Splitting at net.0.bias ... Success.\n",
      "  Splitting at net.2.bias ... Success.\n",
      "\n",
      "Testing SimpleCNN:\n",
      "Legal split points: ['conv.0.bias', 'conv.0.weight', 'conv.2.bias', 'conv.2.weight', 'fc.bias', 'fc.weight']\n",
      "Safe split points: ['fc.bias', 'fc.weight']\n",
      "  Splitting at fc.bias ... Success.\n",
      "  Splitting at fc.weight ... Success.\n",
      "\n",
      "Testing SimpleRNN:\n",
      "Legal split points: ['fc.bias', 'fc.weight', 'lstm.bias_hh_l0', 'lstm.bias_ih_l0', 'lstm.weight_hh_l0', 'lstm.weight_ih_l0']\n",
      "Safe split points: []\n",
      "\n",
      "Testing MiniViT:\n",
      "Legal split points: ['blocks.0.mlp.0.bias', 'blocks.0.mlp.0.weight', 'blocks.0.mlp.2.bias', 'blocks.0.mlp.2.weight', 'blocks.0.norm1.bias', 'blocks.0.norm1.weight', 'blocks.0.norm2.bias', 'blocks.0.norm2.weight', 'blocks.1.mlp.0.bias', 'blocks.1.mlp.0.weight', 'blocks.1.mlp.2.bias', 'blocks.1.mlp.2.weight', 'blocks.1.norm1.bias', 'blocks.1.norm1.weight', 'blocks.1.norm2.bias', 'blocks.1.norm2.weight', 'head.bias', 'head.weight', 'norm.bias', 'norm.weight', 'patch_embed.bias', 'patch_embed.weight']\n",
      "Safe split points: []\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from model_splitter import ModelSplitter\n",
    "\n",
    "# --- Models ---\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(20, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 4, 3, padding=1),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        self.fc = nn.Linear(4, 5)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(10, 20, batch_first=True)\n",
    "        self.fc = nn.Linear(20, 5)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1])\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, heads=2, mlp_ratio=2):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = nn.MultiheadAttention(dim, heads, batch_first=True)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, dim * mlp_ratio),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim * mlp_ratio, dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.norm1(x), self.norm1(x), self.norm1(x))[0]\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "class MiniViT(nn.Module):\n",
    "    def __init__(self, image_size=28, patch_size=7, dim=64, depth=2, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.patch_embed = nn.Conv2d(1, dim, kernel_size=patch_size, stride=patch_size)\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "\n",
    "        self.blocks = nn.Sequential(*[TransformerBlock(dim) for _ in range(depth)])\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.head = nn.Linear(dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.size(0)\n",
    "        x = self.patch_embed(x)  # [B, dim, H', W']\n",
    "        x = x.flatten(2).transpose(1, 2)  # [B, N, dim]\n",
    "\n",
    "        cls = self.cls_token.expand(B, -1, -1)  # [B, 1, dim]\n",
    "        x = torch.cat([cls, x], dim=1) + self.pos_embed  # [B, N+1, dim]\n",
    "\n",
    "        x = self.blocks(x)\n",
    "        x = self.norm(x[:, 0])  # take cls token\n",
    "        return self.head(x)\n",
    "\n",
    "# --- Inputs ---\n",
    "nn_in = torch.randn(5, 20)\n",
    "cnn_in = torch.randn(5, 1, 8, 8)\n",
    "rnn_in = torch.randn(5, 7, 10)\n",
    "vit_in = torch.randn(5, 1, 28, 28)  # corrected for 28x28 patching\n",
    "\n",
    "# --- Test function ---\n",
    "def test_model(model, sample_input, name):\n",
    "    print(f\"\\nTesting {name}:\")\n",
    "    splitter = ModelSplitter(model, sample_input)\n",
    "    print(\"Legal split points:\", sorted(splitter.legal_splits))\n",
    "\n",
    "    safe_points = splitter.get_safe_split_points()\n",
    "    print(\"Safe split points:\", sorted(safe_points))\n",
    "\n",
    "    for point in safe_points:\n",
    "        print(f\"  Splitting at {point} ... \", end=\"\")\n",
    "        try:\n",
    "            _, _ = splitter.split_from_param(point)\n",
    "            print(\"Success.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed. Error: {e}\")\n",
    "\n",
    "\n",
    "# --- Run tests ---\n",
    "test_model(SimpleNN(), nn_in, \"SimpleNN\")\n",
    "test_model(SimpleCNN(), cnn_in, \"SimpleCNN\")\n",
    "test_model(SimpleRNN(), rnn_in, \"SimpleRNN\")\n",
    "test_model(MiniViT(), vit_in, \"MiniViT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a58cce32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available split points:\n",
      "patch_embed.weight\n",
      "patch_embed.bias\n",
      "blocks.0.0.weight\n",
      "blocks.0.0.bias\n",
      "blocks.0.1.weight\n",
      "blocks.0.1.bias\n",
      "blocks.0.3.weight\n",
      "blocks.0.3.bias\n",
      "blocks.1.0.weight\n",
      "blocks.1.0.bias\n",
      "blocks.1.1.weight\n",
      "blocks.1.1.bias\n",
      "blocks.1.3.weight\n",
      "blocks.1.3.bias\n",
      "blocks.2.0.weight\n",
      "blocks.2.0.bias\n",
      "blocks.2.1.weight\n",
      "blocks.2.1.bias\n",
      "blocks.2.3.weight\n",
      "blocks.2.3.bias\n",
      "blocks.3.0.weight\n",
      "blocks.3.0.bias\n",
      "blocks.3.1.weight\n",
      "blocks.3.1.bias\n",
      "blocks.3.3.weight\n",
      "blocks.3.3.bias\n",
      "norm.weight\n",
      "norm.bias\n",
      "\n",
      "Testing split at: patch_embed.weight\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: patch_embed.bias\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.0.0.weight\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.0.0.bias\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.0.1.weight\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.0.1.bias\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.0.3.weight\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.0.3.bias\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.1.0.weight\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.1.0.bias\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.1.1.weight\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.1.1.bias\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.1.3.weight\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.1.3.bias\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.2.0.weight\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.2.0.bias\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.2.1.weight\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.2.1.bias\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.2.3.weight\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.2.3.bias\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.3.0.weight\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.3.0.bias\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.3.1.weight\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.3.1.bias\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.3.3.weight\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: blocks.3.3.bias\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: norm.weight\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n",
      "\n",
      "Testing split at: norm.bias\n",
      "Split successful. Output shape part1: torch.Size([20, 5, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from model_splitter_vit import ViT32BModelSplitter\n",
    "\n",
    "# Example minimal ViT32B model for testing\n",
    "class MiniViT32B(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.patch_embed = nn.Linear(16, 64)  # e.g. 4 patches x 16 dim -> 64 dim\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, 64))\n",
    "        self.blocks = nn.ModuleList([nn.Sequential(\n",
    "            nn.LayerNorm(64),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64)\n",
    "        ) for _ in range(4)])\n",
    "        self.norm = nn.LayerNorm(64)\n",
    "        self.head = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        B = x.shape[0]\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        x = self.norm(x)\n",
    "        x = x[:, 0]\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Setup model and sample input\n",
    "model = MiniViT32B().eval()\n",
    "sample_input = torch.randn(20, 4, 16)  # batch 20, 4 patches, dim 16\n",
    "\n",
    "# Initialize splitter\n",
    "splitter = ViT32BModelSplitter(model, sample_input)\n",
    "\n",
    "print(\"Available split points:\")\n",
    "for sp in splitter.available_split_points():\n",
    "    print(sp)\n",
    "\n",
    "# Test splitting at each split point\n",
    "for sp in splitter.available_split_points():\n",
    "    print(f\"\\nTesting split at: {sp}\")\n",
    "    part1_out, part2_model = splitter.split_from_param(sp)\n",
    "    print(f\"Split successful. Output shape part1: {part1_out.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
