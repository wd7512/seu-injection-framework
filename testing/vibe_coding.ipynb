{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d18cbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import time\n",
    "\n",
    "# Synthetic 2D classification dataset\n",
    "def generate_data(n_samples=1000):\n",
    "    X = torch.randn(n_samples, 2)\n",
    "    y = (X[:, 0] * X[:, 1] > 0).long()\n",
    "    return X, y\n",
    "\n",
    "# Simple MLP for binary classification\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Prepare data\n",
    "X, y = generate_data()\n",
    "dataset = TensorDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25228ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, epochs=5):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for xb, yb in dataloader:\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "model = SimpleNet()\n",
    "train(model, dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80acec90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.000901 seconds\n",
      "Sample logits:\n",
      "tensor([[ 6.9300, -5.3727],\n",
      "        [-0.1109,  0.0112],\n",
      "        [-4.4105,  4.7811],\n",
      "        [-0.7808,  0.7385],\n",
      "        [ 1.3083, -1.2047]])\n",
      "Sample predictions:\n",
      "tensor([0, 1, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# Put model in eval mode\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient computation for inference\n",
    "with torch.no_grad():\n",
    "    start = time.time()\n",
    "    outputs = model(X)\n",
    "    end = time.time()\n",
    "\n",
    "# Process outputs\n",
    "logits = outputs\n",
    "preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "# Baseline metrics\n",
    "print(f\"Inference time: {end - start:.6f} seconds\")\n",
    "print(f\"Sample logits:\\n{logits[:5]}\")\n",
    "print(f\"Sample predictions:\\n{preds[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08aacd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered modules:\n",
      "0 -> Linear(in_features=2, out_features=16, bias=True)\n",
      "1 -> ReLU()\n",
      "2 -> Linear(in_features=16, out_features=2, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# Helper: get modules in forward order\n",
    "def get_forward_modules(model):\n",
    "    if isinstance(model, nn.Sequential):\n",
    "        return list(model._modules.items())\n",
    "    else:\n",
    "        raise NotImplementedError(\"This prototype assumes nn.Sequential-based models.\")\n",
    "        \n",
    "modules = get_forward_modules(model.net)\n",
    "print(\"Ordered modules:\")\n",
    "for name, layer in modules:\n",
    "    print(name, \"->\", layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5c3ad71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net.0.weight\n",
      "net.0.bias\n",
      "net.2.weight\n",
      "net.2.bias\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# See what parameters are available\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "205caa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find split point from parameter name\n",
    "def split_model_at_param(model, param_name):\n",
    "    modules = get_forward_modules(model.net)\n",
    "    \n",
    "    # Flatten layers into parameter lookup\n",
    "    param_to_module_idx = {}\n",
    "    for idx, (mod_name, layer) in enumerate(modules):\n",
    "        for pname, _ in layer.named_parameters():\n",
    "            full_name = f\"net.{mod_name}.{pname}\"\n",
    "            param_to_module_idx[full_name] = idx\n",
    "\n",
    "    # Get split index\n",
    "    split_idx = param_to_module_idx[param_name]\n",
    "\n",
    "    # Create submodels\n",
    "    layers1 = nn.Sequential(*[layer for _, layer in modules[:split_idx]])\n",
    "    layers2 = nn.Sequential(*[layer for _, layer in modules[split_idx:]])\n",
    "\n",
    "    return layers1, layers2\n",
    "\n",
    "# Example split\n",
    "param_to_split = \"net.2.weight\"\n",
    "model1, model2 = split_model_at_param(model, param_to_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca74458c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    full_out = model(X)\n",
    "    part1_out = model1(X)\n",
    "    part2_out = model2(part1_out)\n",
    "\n",
    "# Check match\n",
    "print(torch.allclose(full_out, part2_out, atol=1e-6))  # Should be True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89a3f770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# In a Jupyter cell\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from model_splitter import ModelSplitter\n",
    "\n",
    "# Define toy model\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Generate toy data\n",
    "def generate_data(n=1000):\n",
    "    X = torch.randn(n, 2)\n",
    "    y = (X[:, 0] * X[:, 1] > 0).long()\n",
    "    return X, y\n",
    "\n",
    "X, y = generate_data()\n",
    "model = SimpleNet()\n",
    "\n",
    "# Quick train loop\n",
    "def train(model, X, y, epochs=3):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    for _ in range(epochs):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "train(model, X, y)\n",
    "\n",
    "# Initialize splitter\n",
    "splitter = ModelSplitter(model, X)\n",
    "\n",
    "# Split from a layer (e.g., after first Linear)\n",
    "param_name = \"net.2.weight\"  # start of second Linear layer\n",
    "part1_out, model2 = splitter.split_from_param(param_name)\n",
    "\n",
    "# Optional: demonstrate new usage\n",
    "with torch.no_grad():\n",
    "    out_new = model2(part1_out)\n",
    "    print(torch.allclose(out_new, splitter.baseline_output, atol=1e-6))  # True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a92b42d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full model inference time: 0.011029 sec\n",
      "Model2 (second half) inference time: 0.007837 sec\n",
      "Output identical to baseline: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from model_splitter import ModelSplitter\n",
    "\n",
    "# Define a deeper model\n",
    "class LargeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Generate input\n",
    "X_large = torch.randn(10_000, 2)  # Large batch\n",
    "\n",
    "# Initialize and warm up model\n",
    "model_large = LargeNet()\n",
    "model_large.eval()\n",
    "\n",
    "# Warm-up pass\n",
    "with torch.no_grad():\n",
    "    _ = model_large(X_large)\n",
    "\n",
    "# Baseline full inference time\n",
    "with torch.no_grad():\n",
    "    start = time.time()\n",
    "    baseline_output = model_large(X_large)\n",
    "    end = time.time()\n",
    "\n",
    "print(f\"Full model inference time: {end - start:.6f} sec\")\n",
    "\n",
    "# Split and time only second half\n",
    "splitter = ModelSplitter(model_large, X_large)\n",
    "part1_out, model2 = splitter.split_from_param(\"net.4.weight\")  # Midpoint layer\n",
    "\n",
    "# Time only model2 inference\n",
    "with torch.no_grad():\n",
    "    start = time.time()\n",
    "    output_partial = model2(part1_out)\n",
    "    end = time.time()\n",
    "\n",
    "print(f\"Model2 (second half) inference time: {end - start:.6f} sec\")\n",
    "print(\"Output identical to baseline:\", torch.allclose(output_partial, baseline_output, atol=1e-6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f484a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Repositories\\seu-injection-framework\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Repositories\\seu-injection-framework\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to C:\\Users\\wwden/.cache\\torch\\hub\\checkpoints\\vit_b_16-c867db91.pth\n",
      "  3%|▎         | 9.23M/330M [00:40<24:59, 225kB/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from model_splitter import ModelSplitter\n",
    "import time\n",
    "\n",
    "# 1. Load MNIST and preprocess for ViT (grayscale → RGB, 28x28 → 224x224)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "mnist = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "loader = DataLoader(mnist, batch_size=64, shuffle=False)\n",
    "images, labels = next(iter(loader))\n",
    "\n",
    "# 2. Load pretrained ViT and adapt to MNIST\n",
    "vit = torchvision.models.vit_b_16(pretrained=True)\n",
    "vit.heads = nn.Linear(vit.heads.in_features, 10)  # Replace classifier head\n",
    "vit.eval()\n",
    "\n",
    "# 3. Run full inference\n",
    "with torch.no_grad():\n",
    "    start = time.time()\n",
    "    full_output = vit(images)\n",
    "    end = time.time()\n",
    "print(f\"Full ViT inference time: {end - start:.6f} sec\")\n",
    "\n",
    "# 4. Use ModelSplitter on ViT\n",
    "splitter = ModelSplitter(vit, images)\n",
    "\n",
    "# Inspect available param names (optional)\n",
    "# for name, _ in vit.named_parameters(): print(name)\n",
    "\n",
    "# Split before classifier head\n",
    "part1_out, model2 = splitter.split_from_param(\"heads.weight\")\n",
    "\n",
    "# 5. Run partial inference (classifier only)\n",
    "with torch.no_grad():\n",
    "    start = time.time()\n",
    "    partial_output = model2(part1_out)\n",
    "    end = time.time()\n",
    "\n",
    "print(f\"ViT head inference time: {end - start:.6f} sec\")\n",
    "print(\"Output matches full inference:\", torch.allclose(partial_output, full_output, atol=1e-6))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
