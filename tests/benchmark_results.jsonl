{"timestamp": "2025-06-13 22:07:35", "os": "Windows-10-10.0.22631-SP0", "cpu": "Intel64 Family 6 Model 154 Stepping 3, GenuineIntel", "cpu_count": 14, "cpu_count_logical": 20, "gpu": "NVIDIA GeForce RTX 3070 Ti Laptop GPU", "device": "cuda", "model": "SmallConvNet CNN (3x64x64 input)", "results": [{"batch_size": 1, "total_time_50_forward_passes": 0.016004562377929688, "avg_time_per_forward_pass": 0.00032009124755859374, "avg_time_per_image": 0.00032009124755859374}, {"batch_size": 8, "total_time_50_forward_passes": 0.031256914138793945, "avg_time_per_forward_pass": 0.0006251382827758789, "avg_time_per_image": 7.814228534698486e-05}, {"batch_size": 32, "total_time_50_forward_passes": 0.04732966423034668, "avg_time_per_forward_pass": 0.0009465932846069336, "avg_time_per_image": 2.9581040143966676e-05}, {"batch_size": 128, "total_time_50_forward_passes": 0.17546772956848145, "avg_time_per_forward_pass": 0.0035093545913696287, "avg_time_per_image": 2.7416832745075224e-05}], "compiled_results": [{"error": "torch.compile failed with: backend='inductor' raised:\nRuntimeError: Cannot find a working triton installation. More information on installing Triton can be found at https://github.com/openai/triton\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n"}]}
{"timestamp": "2025-06-13 22:07:40", "os": "Windows-10-10.0.22631-SP0", "cpu": "Intel64 Family 6 Model 154 Stepping 3, GenuineIntel", "cpu_count": 14, "cpu_count_logical": 20, "gpu": "NVIDIA GeForce RTX 3070 Ti Laptop GPU", "device": "cuda", "model": "SmallConvNet CNN (3x64x64 input)", "results": [{"batch_size": 1, "total_time_50_forward_passes": 0.03041243553161621, "avg_time_per_forward_pass": 0.0006082487106323242, "avg_time_per_image": 0.0006082487106323242}, {"batch_size": 8, "total_time_50_forward_passes": 0.02000594139099121, "avg_time_per_forward_pass": 0.0004001188278198242, "avg_time_per_image": 5.001485347747803e-05}, {"batch_size": 32, "total_time_50_forward_passes": 0.05006885528564453, "avg_time_per_forward_pass": 0.0010013771057128906, "avg_time_per_image": 3.129303455352783e-05}, {"batch_size": 128, "total_time_50_forward_passes": 0.17235755920410156, "avg_time_per_forward_pass": 0.003447151184082031, "avg_time_per_image": 2.693086862564087e-05}], "compiled_results": [{"error": "torch.compile failed with: backend='inductor' raised:\nRuntimeError: Cannot find a working triton installation. More information on installing Triton can be found at https://github.com/openai/triton\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n"}]}
{"timestamp": "2025-06-13 22:07:45", "os": "Windows-10-10.0.22631-SP0", "cpu": "Intel64 Family 6 Model 154 Stepping 3, GenuineIntel", "cpu_count": 14, "cpu_count_logical": 20, "gpu": "NVIDIA GeForce RTX 3070 Ti Laptop GPU", "device": "cuda", "model": "SmallConvNet CNN (3x64x64 input)", "results": [{"batch_size": 1, "total_time_50_forward_passes": 0.03029632568359375, "avg_time_per_forward_pass": 0.000605926513671875, "avg_time_per_image": 0.000605926513671875}, {"batch_size": 8, "total_time_50_forward_passes": 0.020621061325073242, "avg_time_per_forward_pass": 0.00041242122650146483, "avg_time_per_image": 5.1552653312683104e-05}, {"batch_size": 32, "total_time_50_forward_passes": 0.05094003677368164, "avg_time_per_forward_pass": 0.0010188007354736328, "avg_time_per_image": 3.1837522983551024e-05}, {"batch_size": 128, "total_time_50_forward_passes": 0.17199444770812988, "avg_time_per_forward_pass": 0.0034398889541625978, "avg_time_per_image": 2.6874132454395295e-05}], "compiled_results": [{"error": "torch.compile failed with: backend='inductor' raised:\nRuntimeError: Cannot find a working triton installation. More information on installing Triton can be found at https://github.com/openai/triton\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n"}]}
