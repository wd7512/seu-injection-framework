{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da7a67ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n"
     ]
    }
   ],
   "source": [
    "# assuming we want to run the programme overnight i.e. 8hrs\n",
    "\n",
    "total_time = 8 * 60 * 60 # in seconds\n",
    "time_for_5k = 60 # in seconds\n",
    "\n",
    "real_5k_time = time_for_5k * 1.1 # add any overhead\n",
    "\n",
    "total_forward_passes = total_time // time_for_5k\n",
    "\n",
    "print(total_forward_passes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfd743a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: ViT_B_32\n",
      "Total Parameters: 88,224,232\n",
      "\n",
      "Group                                                        Count                Shape         Each           Total\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "conv_proj.weight                                                 1     (768, 3, 32, 32)    2,359,296       2,359,296\n",
      "encoder_layer_#.mlp.0.weight                                    12          (3072, 768)    2,359,296      28,311,552\n",
      "encoder_layer_#.mlp.3.weight                                    12          (768, 3072)    2,359,296      28,311,552\n",
      "encoder_layer_#.self_attention.in_proj_weight                   12          (2304, 768)    1,769,472      21,233,664\n",
      "heads.head.weight                                                1          (1000, 768)      768,000         768,000\n",
      "encoder_layer_#.self_attention.out_proj.weight                  12           (768, 768)      589,824       7,077,888\n",
      "encoder.pos_embedding                                            1         (1, 50, 768)       38,400          38,400\n",
      "encoder_layer_#.mlp.0.bias                                      12              (3072,)        3,072          36,864\n",
      "encoder_layer_#.self_attention.in_proj_bias                     12              (2304,)        2,304          27,648\n",
      "heads.head.bias                                                  1              (1000,)        1,000           1,000\n",
      "class_token                                                      1          (1, 1, 768)          768             768\n",
      "conv_proj.bias                                                   1               (768,)          768             768\n",
      "encoder_layer_#.ln_1.weight                                     12               (768,)          768           9,216\n",
      "encoder_layer_#.ln_1.bias                                       12               (768,)          768           9,216\n",
      "encoder_layer_#.self_attention.out_proj.bias                    12               (768,)          768           9,216\n",
      "encoder_layer_#.ln_2.weight                                     12               (768,)          768           9,216\n",
      "encoder_layer_#.ln_2.bias                                       12               (768,)          768           9,216\n",
      "encoder_layer_#.mlp.3.bias                                      12               (768,)          768           9,216\n",
      "encoder.ln.weight                                                1               (768,)          768             768\n",
      "encoder.ln.bias                                                  1               (768,)          768             768\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from torchvision.models import vit_b_32, ViT_B_32_Weights\n",
    "\n",
    "model = vit_b_32(weights=ViT_B_32_Weights.IMAGENET1K_V1)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nModel: ViT_B_32\")\n",
    "print(f\"Total Parameters: {total_params:,}\\n\")\n",
    "\n",
    "grouped = defaultdict(list)\n",
    "\n",
    "# Normalize and group parameter names\n",
    "for name, p in model.named_parameters():\n",
    "    # Replace numeric indices with # using regex\n",
    "    normalized = re.sub(r'encoder\\.layers\\.encoder_layer_\\d+', 'encoder_layer_#', name)\n",
    "    grouped[normalized].append((name, tuple(p.shape), p.numel()))\n",
    "\n",
    "# Prepare summary\n",
    "summary = []\n",
    "for group, entries in grouped.items():\n",
    "    count = len(entries)\n",
    "    total = sum(e[2] for e in entries)\n",
    "    shape = entries[0][1]\n",
    "    per_param = entries[0][2]\n",
    "    summary.append((group, count, shape, per_param, total))\n",
    "\n",
    "# Sort by total parameters in descending order\n",
    "summary.sort(key=lambda x: x[3], reverse=True)\n",
    "\n",
    "# Print formatted table\n",
    "print(f\"{'Group':<60} {'Count':>5} {'Shape':>20} {'Each':>12} {'Total':>15}\")\n",
    "print(\"-\" * 120)\n",
    "for group, count, shape, per_param, total in summary:\n",
    "    print(f\"{group:<60} {count:5} {str(shape):>20} {per_param:12,} {total:15,}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
